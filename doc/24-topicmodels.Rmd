## Topic-Modelle {#topicmodelle}

Um die im vorangegangen Abschnitt angesprochenen Themenhistorien der Nutzer zu erzeugen, werden Topic-Modelle eingesetzt.
Dabei handelt es sich um statistische Modelle, die es ermöglichen, thematische Assoziationen von Texten aufzudecken, ohne eine Inhaltsanalyse "von Hand" durchführen zu müssen.
Damit lassen sich vor allem große Datenmengen strukturieren, einordnen und erschließen.
Zu beachten ist vor allem, dass die Verfahren kein Vorwissen über die zugrundeliegende Themenstruktur besitzen, sondern diese als Teil des Prozesses selbst entdecken.  

#### *Text as data*
Topic-Modelling ist einer Reihe von Verfahren zuzuordnen, die Text als Daten auffassen, auf denen sich wie auf numerischen Daten Berechnungen ausführen und Modelle erzeugen lassen.
Ein Beispiel für ein solches Verfahren stellt *tf-idf*\ [@Salton1983, S. 63] dar, ein Gewichtungsverfahren für Wörter in einer Sammlung von Dokumenten.
Hierbei wird jedes Vorkommen eines Begriffs innerhalb eines Dokuments gezählt (*term frequency*).
Die Anzahl an Dokumenten dividiert durch die Zahl der Dokumenten, welche diesen Begriff enthalten, gibt die *inverse document frequency*.
Das Produkt dieser beiden Größen ergibt eine Gewichtung dieses Wortes innerhalb des Korpus.
Dabei wird Begriffen, die in nur wenigen Dokumenten häufig vorkommen, ein höheres Gewicht beigemessen; damit werden insbesondere Funktionswörter wie Artikel und Konjunktionen bestraft, die wenig Informationsgehalt besitzen.
Diese Gewichtung von Begriffen liefert einen Indikator, welche Worte innerhalb eines Dokuments Bedeutung tragen.

#### *Mixed membership*-Modelle
Gewichtende Verfahren wie tf-idf ermöglichen zwar eine erste grobe Einschätzung, worum es in einem Dokument tendenziell geht, allerdings bilden sie menschliches Verständnis von Themenstrukturen eher schlecht ab.
Es kommt eher selten vor, dass ein Dokument, bspw. ein Zeitungsartikel, ausschließlich ein Thema zum Gegenstand hat und sich dieses ausschließlich über die numerische Rangfolge charakteristischer Schlagworte definieren lässt.
Meist entsprechen Dokumente eher einer Zusammensetzung verschiedener Themenkomplexe; so handelt der Zeitungsartikel möglicherweise zu je verschiedenen Anteilen von "Wirtschaft" und "Politik".
Diesem Umstand tragen *mixed membership*-Modelle Rechnung, indem sie statt eines einzelnen Themas zulassen, dass ein Dokument in mehreren Themenkomplexen enthalten ist.  
Zu beachten ist, dass diese Verfahren keineswegs auf textuelle Daten beschränkt sind und auch in anderen Gebieten Anwendung finden, wie etwa der Genetik oder Computergrafik\ [@Blei2012].

#### Latent Dirichlet Allocation (LDA)
Auch LDA\ [@Blei2012] zählt zur Klasse der *mixed membership*-Modelle.
Diesem Ansatz liegt die Idee zugrunde, dass Dokumente durch einen generativen probabilistischen Prozess erzeugt werden.
Dabei stellen Topics eine Multinomialverteilung über den Wörtern eines Vokabulars dar, und jedes Dokument ist eine Multinomialverteilung über diese Topics; ein Dokument enthält also mehrere Topics zu unterschiedlichen Anteilen.


In der vorliegenden Arbeit wird ein algorithmisch erstelltes Topic-Modell genutzt

* Text as data

* informationsgewinnung aus textuellen daten

* bei großen unkategorisierten dammlungen an dokumenten schwer, "Sinn" zu gewinnen

* IR verfahren helfen, Dokumente maschinell auszuwerten bzw. für weitere menschliche verarbeitung vorzubereiten

* LDA liefert keine "Gold Standard" Topics, sondern gliedert lediglich einen Korpus von Dokumenten

* LDA geht davon aus, dass jedes Dokument Mischung verschiedener Topcis enthält

* Topic besteht aus Verteilung vopn Wörtern

* LDA beschreibt generativen Prozess: Dokument wird aus diesen Parametern erzeugt

* Umkehrung erhält man a-posteriori-verteilung, die sich abschätzen lässt


LDA reiht sich ein in Verfahren wie tf-idf oder Latent Semantic Analysis.